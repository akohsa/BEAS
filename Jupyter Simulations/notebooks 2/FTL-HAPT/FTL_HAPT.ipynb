{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FTL_HAPT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YCACJf4p4EU",
        "outputId": "67dc07c1-ce25-41b0-fb99-44182c967a73"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHPvJ-4uZhZr",
        "outputId": "d1b369c9-3e2c-4fb8-a303-747952ecfa5b"
      },
      "source": [
        "%cd drive/MyDrive/FTSL/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1CI1F_BNtclDb589EJiZx_ypJ_TSazyxZ/FTSL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cMZBKO9aSrk",
        "outputId": "f0f8c4c2-f89a-48c4-9b39-8b4eb0f9c54a"
      },
      "source": [
        "!pip3 install tensorflow_model_optimization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "clxtnHJcacpX",
        "outputId": "044e0cfc-36cd-405f-a37d-5774969b37ec"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "\n",
        "import cv2\n",
        "import keras\n",
        "import numpy as np\n",
        "from numpy import dstack \n",
        "import pandas as pd\n",
        "from keras.layers import (Conv2D, Dense, Dropout, Flatten, GaussianNoise,\n",
        "                          MaxPooling2D, BatchNormalization)\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils, to_categorical\n",
        "from matplotlib import pyplot\n",
        "from numpy import dstack, mean, std\n",
        "from pandas import read_csv\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "%matplotlib inline\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import plotly.express as px\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from scipy.spatial.distance import euclidean as euc\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
        "\n",
        "init_notebook_mode(connected=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "SSf8Lzamadv2",
        "outputId": "a2d352e6-0a1b-470f-a187-640d79262574"
      },
      "source": [
        "DF_train = pd.read_csv('./train.csv')\n",
        "DF_test = pd.read_csv('./test.csv')\n",
        "DF = pd.concat([DF_train, DF_test], axis = 0)\n",
        "DF = DF.sample(frac=1).reset_index(drop=True)\n",
        "DF"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tBodyAcc-mean()-X</th>\n",
              "      <th>tBodyAcc-mean()-Y</th>\n",
              "      <th>tBodyAcc-mean()-Z</th>\n",
              "      <th>tBodyAcc-std()-X</th>\n",
              "      <th>tBodyAcc-std()-Y</th>\n",
              "      <th>tBodyAcc-std()-Z</th>\n",
              "      <th>tBodyAcc-mad()-X</th>\n",
              "      <th>tBodyAcc-mad()-Y</th>\n",
              "      <th>tBodyAcc-mad()-Z</th>\n",
              "      <th>tBodyAcc-max()-X</th>\n",
              "      <th>tBodyAcc-max()-Y</th>\n",
              "      <th>tBodyAcc-max()-Z</th>\n",
              "      <th>tBodyAcc-min()-X</th>\n",
              "      <th>tBodyAcc-min()-Y</th>\n",
              "      <th>tBodyAcc-min()-Z</th>\n",
              "      <th>tBodyAcc-sma()</th>\n",
              "      <th>tBodyAcc-energy()-X</th>\n",
              "      <th>tBodyAcc-energy()-Y</th>\n",
              "      <th>tBodyAcc-energy()-Z</th>\n",
              "      <th>tBodyAcc-iqr()-X</th>\n",
              "      <th>tBodyAcc-iqr()-Y</th>\n",
              "      <th>tBodyAcc-iqr()-Z</th>\n",
              "      <th>tBodyAcc-entropy()-X</th>\n",
              "      <th>tBodyAcc-entropy()-Y</th>\n",
              "      <th>tBodyAcc-entropy()-Z</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-X,4</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-Y,4</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,1</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,2</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,3</th>\n",
              "      <th>tBodyAcc-arCoeff()-Z,4</th>\n",
              "      <th>tBodyAcc-correlation()-X,Y</th>\n",
              "      <th>tBodyAcc-correlation()-X,Z</th>\n",
              "      <th>tBodyAcc-correlation()-Y,Z</th>\n",
              "      <th>...</th>\n",
              "      <th>fBodyBodyAccJerkMag-entropy()</th>\n",
              "      <th>fBodyBodyAccJerkMag-maxInds</th>\n",
              "      <th>fBodyBodyAccJerkMag-meanFreq()</th>\n",
              "      <th>fBodyBodyAccJerkMag-skewness()</th>\n",
              "      <th>fBodyBodyAccJerkMag-kurtosis()</th>\n",
              "      <th>fBodyBodyGyroMag-mean()</th>\n",
              "      <th>fBodyBodyGyroMag-std()</th>\n",
              "      <th>fBodyBodyGyroMag-mad()</th>\n",
              "      <th>fBodyBodyGyroMag-max()</th>\n",
              "      <th>fBodyBodyGyroMag-min()</th>\n",
              "      <th>fBodyBodyGyroMag-sma()</th>\n",
              "      <th>fBodyBodyGyroMag-energy()</th>\n",
              "      <th>fBodyBodyGyroMag-iqr()</th>\n",
              "      <th>fBodyBodyGyroMag-entropy()</th>\n",
              "      <th>fBodyBodyGyroMag-maxInds</th>\n",
              "      <th>fBodyBodyGyroMag-meanFreq()</th>\n",
              "      <th>fBodyBodyGyroMag-skewness()</th>\n",
              "      <th>fBodyBodyGyroMag-kurtosis()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-mean()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-std()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-mad()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-max()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-min()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-sma()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-energy()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-iqr()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-entropy()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-maxInds</th>\n",
              "      <th>fBodyBodyGyroJerkMag-meanFreq()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
              "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
              "      <th>angle(tBodyAccMean,gravity)</th>\n",
              "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
              "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
              "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
              "      <th>angle(X,gravityMean)</th>\n",
              "      <th>angle(Y,gravityMean)</th>\n",
              "      <th>angle(Z,gravityMean)</th>\n",
              "      <th>subject</th>\n",
              "      <th>Activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.275800</td>\n",
              "      <td>0.001837</td>\n",
              "      <td>-0.136288</td>\n",
              "      <td>-0.036102</td>\n",
              "      <td>0.284849</td>\n",
              "      <td>-0.141780</td>\n",
              "      <td>-0.164648</td>\n",
              "      <td>0.147255</td>\n",
              "      <td>-0.175408</td>\n",
              "      <td>0.396171</td>\n",
              "      <td>-0.027748</td>\n",
              "      <td>-0.300698</td>\n",
              "      <td>0.060519</td>\n",
              "      <td>-0.289720</td>\n",
              "      <td>0.007840</td>\n",
              "      <td>0.020844</td>\n",
              "      <td>-0.534534</td>\n",
              "      <td>-0.681412</td>\n",
              "      <td>-0.666986</td>\n",
              "      <td>-0.527540</td>\n",
              "      <td>-0.370368</td>\n",
              "      <td>-0.209740</td>\n",
              "      <td>0.028807</td>\n",
              "      <td>0.554978</td>\n",
              "      <td>0.206736</td>\n",
              "      <td>-0.203810</td>\n",
              "      <td>0.165127</td>\n",
              "      <td>-0.171441</td>\n",
              "      <td>0.297230</td>\n",
              "      <td>-0.054280</td>\n",
              "      <td>-0.012814</td>\n",
              "      <td>0.288070</td>\n",
              "      <td>-0.032690</td>\n",
              "      <td>0.248977</td>\n",
              "      <td>-0.132112</td>\n",
              "      <td>0.342373</td>\n",
              "      <td>-0.283569</td>\n",
              "      <td>-0.650882</td>\n",
              "      <td>-0.290329</td>\n",
              "      <td>0.175495</td>\n",
              "      <td>...</td>\n",
              "      <td>0.487582</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.109912</td>\n",
              "      <td>0.383082</td>\n",
              "      <td>0.126106</td>\n",
              "      <td>-0.445692</td>\n",
              "      <td>-0.395702</td>\n",
              "      <td>-0.371305</td>\n",
              "      <td>-0.517765</td>\n",
              "      <td>-0.866404</td>\n",
              "      <td>-0.445692</td>\n",
              "      <td>-0.786441</td>\n",
              "      <td>-0.461694</td>\n",
              "      <td>0.475231</td>\n",
              "      <td>-0.948718</td>\n",
              "      <td>-0.189139</td>\n",
              "      <td>-0.317616</td>\n",
              "      <td>-0.704673</td>\n",
              "      <td>-0.621752</td>\n",
              "      <td>-0.586926</td>\n",
              "      <td>-0.579769</td>\n",
              "      <td>-0.555529</td>\n",
              "      <td>-0.733606</td>\n",
              "      <td>-0.621752</td>\n",
              "      <td>-0.916470</td>\n",
              "      <td>-0.561092</td>\n",
              "      <td>0.328573</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.260239</td>\n",
              "      <td>0.132597</td>\n",
              "      <td>-0.154372</td>\n",
              "      <td>0.175643</td>\n",
              "      <td>0.513423</td>\n",
              "      <td>0.968562</td>\n",
              "      <td>-0.253992</td>\n",
              "      <td>-0.673257</td>\n",
              "      <td>0.323866</td>\n",
              "      <td>0.015887</td>\n",
              "      <td>2</td>\n",
              "      <td>WALKING_DOWNSTAIRS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.239223</td>\n",
              "      <td>-0.031477</td>\n",
              "      <td>-0.105473</td>\n",
              "      <td>-0.895730</td>\n",
              "      <td>-0.910200</td>\n",
              "      <td>-0.944044</td>\n",
              "      <td>-0.907762</td>\n",
              "      <td>-0.913140</td>\n",
              "      <td>-0.943929</td>\n",
              "      <td>-0.908422</td>\n",
              "      <td>-0.534366</td>\n",
              "      <td>-0.782379</td>\n",
              "      <td>0.702528</td>\n",
              "      <td>0.636651</td>\n",
              "      <td>0.824235</td>\n",
              "      <td>-0.913950</td>\n",
              "      <td>-0.993854</td>\n",
              "      <td>-0.997755</td>\n",
              "      <td>-0.997822</td>\n",
              "      <td>-0.937716</td>\n",
              "      <td>-0.932928</td>\n",
              "      <td>-0.948821</td>\n",
              "      <td>0.064764</td>\n",
              "      <td>-0.434452</td>\n",
              "      <td>-0.326168</td>\n",
              "      <td>-0.293357</td>\n",
              "      <td>-0.016060</td>\n",
              "      <td>0.372616</td>\n",
              "      <td>-0.303446</td>\n",
              "      <td>-0.239328</td>\n",
              "      <td>-0.014961</td>\n",
              "      <td>0.432186</td>\n",
              "      <td>-0.310430</td>\n",
              "      <td>-0.017772</td>\n",
              "      <td>-0.097186</td>\n",
              "      <td>0.398385</td>\n",
              "      <td>-0.444456</td>\n",
              "      <td>-0.423243</td>\n",
              "      <td>-0.862583</td>\n",
              "      <td>0.209881</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.898000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.002040</td>\n",
              "      <td>-0.367677</td>\n",
              "      <td>-0.747877</td>\n",
              "      <td>-0.929916</td>\n",
              "      <td>-0.896370</td>\n",
              "      <td>-0.915577</td>\n",
              "      <td>-0.879163</td>\n",
              "      <td>-0.916564</td>\n",
              "      <td>-0.929916</td>\n",
              "      <td>-0.994477</td>\n",
              "      <td>-0.962295</td>\n",
              "      <td>-0.296197</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.189233</td>\n",
              "      <td>0.341697</td>\n",
              "      <td>0.080852</td>\n",
              "      <td>-0.959017</td>\n",
              "      <td>-0.966154</td>\n",
              "      <td>-0.962918</td>\n",
              "      <td>-0.972842</td>\n",
              "      <td>-0.970014</td>\n",
              "      <td>-0.959017</td>\n",
              "      <td>-0.999121</td>\n",
              "      <td>-0.965801</td>\n",
              "      <td>-0.497993</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.074829</td>\n",
              "      <td>-0.362611</td>\n",
              "      <td>-0.746751</td>\n",
              "      <td>0.501495</td>\n",
              "      <td>0.112612</td>\n",
              "      <td>-0.118652</td>\n",
              "      <td>0.487422</td>\n",
              "      <td>0.385570</td>\n",
              "      <td>-0.631058</td>\n",
              "      <td>-0.335879</td>\n",
              "      <td>20</td>\n",
              "      <td>LAYING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.272430</td>\n",
              "      <td>-0.017791</td>\n",
              "      <td>-0.105656</td>\n",
              "      <td>-0.986900</td>\n",
              "      <td>-0.987047</td>\n",
              "      <td>-0.990689</td>\n",
              "      <td>-0.987456</td>\n",
              "      <td>-0.986189</td>\n",
              "      <td>-0.990150</td>\n",
              "      <td>-0.932266</td>\n",
              "      <td>-0.570833</td>\n",
              "      <td>-0.810314</td>\n",
              "      <td>0.838099</td>\n",
              "      <td>0.689392</td>\n",
              "      <td>0.847325</td>\n",
              "      <td>-0.988626</td>\n",
              "      <td>-0.999853</td>\n",
              "      <td>-0.999918</td>\n",
              "      <td>-0.999824</td>\n",
              "      <td>-0.988616</td>\n",
              "      <td>-0.985671</td>\n",
              "      <td>-0.988558</td>\n",
              "      <td>-0.479287</td>\n",
              "      <td>-0.640648</td>\n",
              "      <td>-0.519156</td>\n",
              "      <td>-0.048398</td>\n",
              "      <td>-0.027917</td>\n",
              "      <td>0.078993</td>\n",
              "      <td>0.044116</td>\n",
              "      <td>0.278088</td>\n",
              "      <td>-0.139673</td>\n",
              "      <td>0.134070</td>\n",
              "      <td>0.152491</td>\n",
              "      <td>0.427384</td>\n",
              "      <td>-0.209650</td>\n",
              "      <td>0.199601</td>\n",
              "      <td>-0.210897</td>\n",
              "      <td>0.076618</td>\n",
              "      <td>-0.173813</td>\n",
              "      <td>-0.454288</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.777778</td>\n",
              "      <td>0.503482</td>\n",
              "      <td>-0.797450</td>\n",
              "      <td>-0.971363</td>\n",
              "      <td>-0.991585</td>\n",
              "      <td>-0.992080</td>\n",
              "      <td>-0.992464</td>\n",
              "      <td>-0.990412</td>\n",
              "      <td>-0.994642</td>\n",
              "      <td>-0.991585</td>\n",
              "      <td>-0.999929</td>\n",
              "      <td>-0.993729</td>\n",
              "      <td>-0.872354</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.254812</td>\n",
              "      <td>-0.149628</td>\n",
              "      <td>-0.409165</td>\n",
              "      <td>-0.994775</td>\n",
              "      <td>-0.996325</td>\n",
              "      <td>-0.995893</td>\n",
              "      <td>-0.997219</td>\n",
              "      <td>-0.992951</td>\n",
              "      <td>-0.994775</td>\n",
              "      <td>-0.999975</td>\n",
              "      <td>-0.995476</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.587302</td>\n",
              "      <td>0.506066</td>\n",
              "      <td>-0.647823</td>\n",
              "      <td>-0.879260</td>\n",
              "      <td>-0.248694</td>\n",
              "      <td>0.059215</td>\n",
              "      <td>-0.761151</td>\n",
              "      <td>0.121526</td>\n",
              "      <td>0.649466</td>\n",
              "      <td>-0.358785</td>\n",
              "      <td>-0.651573</td>\n",
              "      <td>27</td>\n",
              "      <td>LAYING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.266606</td>\n",
              "      <td>-0.019494</td>\n",
              "      <td>-0.107841</td>\n",
              "      <td>-0.992436</td>\n",
              "      <td>-0.993846</td>\n",
              "      <td>-0.996191</td>\n",
              "      <td>-0.994043</td>\n",
              "      <td>-0.992985</td>\n",
              "      <td>-0.997009</td>\n",
              "      <td>-0.932105</td>\n",
              "      <td>-0.578692</td>\n",
              "      <td>-0.824597</td>\n",
              "      <td>0.843280</td>\n",
              "      <td>0.691128</td>\n",
              "      <td>0.841394</td>\n",
              "      <td>-0.994311</td>\n",
              "      <td>-0.999915</td>\n",
              "      <td>-0.999959</td>\n",
              "      <td>-0.999946</td>\n",
              "      <td>-0.996149</td>\n",
              "      <td>-0.992103</td>\n",
              "      <td>-0.997196</td>\n",
              "      <td>-0.725466</td>\n",
              "      <td>-0.842606</td>\n",
              "      <td>-0.643860</td>\n",
              "      <td>0.075167</td>\n",
              "      <td>-0.039470</td>\n",
              "      <td>-0.039687</td>\n",
              "      <td>0.152492</td>\n",
              "      <td>0.334921</td>\n",
              "      <td>-0.194988</td>\n",
              "      <td>0.125675</td>\n",
              "      <td>0.225354</td>\n",
              "      <td>0.694355</td>\n",
              "      <td>-0.174506</td>\n",
              "      <td>0.217981</td>\n",
              "      <td>0.224933</td>\n",
              "      <td>0.014867</td>\n",
              "      <td>-0.114894</td>\n",
              "      <td>-0.047842</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.873016</td>\n",
              "      <td>0.446709</td>\n",
              "      <td>-0.670225</td>\n",
              "      <td>-0.926400</td>\n",
              "      <td>-0.995114</td>\n",
              "      <td>-0.993907</td>\n",
              "      <td>-0.995086</td>\n",
              "      <td>-0.992419</td>\n",
              "      <td>-0.993972</td>\n",
              "      <td>-0.995114</td>\n",
              "      <td>-0.999960</td>\n",
              "      <td>-0.997873</td>\n",
              "      <td>-0.924075</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.244917</td>\n",
              "      <td>-0.021919</td>\n",
              "      <td>-0.331846</td>\n",
              "      <td>-0.997262</td>\n",
              "      <td>-0.996805</td>\n",
              "      <td>-0.996380</td>\n",
              "      <td>-0.997784</td>\n",
              "      <td>-0.995000</td>\n",
              "      <td>-0.997262</td>\n",
              "      <td>-0.999987</td>\n",
              "      <td>-0.996548</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.841270</td>\n",
              "      <td>0.270825</td>\n",
              "      <td>-0.505108</td>\n",
              "      <td>-0.834955</td>\n",
              "      <td>0.023997</td>\n",
              "      <td>-0.908555</td>\n",
              "      <td>0.095539</td>\n",
              "      <td>0.236185</td>\n",
              "      <td>0.739129</td>\n",
              "      <td>-0.216902</td>\n",
              "      <td>-0.782459</td>\n",
              "      <td>22</td>\n",
              "      <td>LAYING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.212787</td>\n",
              "      <td>-0.048130</td>\n",
              "      <td>-0.121001</td>\n",
              "      <td>-0.041373</td>\n",
              "      <td>0.052449</td>\n",
              "      <td>-0.585361</td>\n",
              "      <td>-0.100714</td>\n",
              "      <td>0.023353</td>\n",
              "      <td>-0.554707</td>\n",
              "      <td>0.219814</td>\n",
              "      <td>-0.112286</td>\n",
              "      <td>-0.599942</td>\n",
              "      <td>0.227870</td>\n",
              "      <td>0.003324</td>\n",
              "      <td>0.604873</td>\n",
              "      <td>-0.087260</td>\n",
              "      <td>-0.538743</td>\n",
              "      <td>-0.784212</td>\n",
              "      <td>-0.919178</td>\n",
              "      <td>-0.233972</td>\n",
              "      <td>-0.282684</td>\n",
              "      <td>-0.479764</td>\n",
              "      <td>0.098014</td>\n",
              "      <td>0.333651</td>\n",
              "      <td>0.036822</td>\n",
              "      <td>-0.719616</td>\n",
              "      <td>0.686123</td>\n",
              "      <td>-0.544138</td>\n",
              "      <td>0.361033</td>\n",
              "      <td>-0.606018</td>\n",
              "      <td>0.536557</td>\n",
              "      <td>-0.148080</td>\n",
              "      <td>-0.015721</td>\n",
              "      <td>-0.035675</td>\n",
              "      <td>-0.144434</td>\n",
              "      <td>0.457046</td>\n",
              "      <td>-0.306473</td>\n",
              "      <td>-0.251215</td>\n",
              "      <td>-0.051896</td>\n",
              "      <td>0.048952</td>\n",
              "      <td>...</td>\n",
              "      <td>0.323401</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.026460</td>\n",
              "      <td>0.098804</td>\n",
              "      <td>-0.279712</td>\n",
              "      <td>-0.504324</td>\n",
              "      <td>-0.404650</td>\n",
              "      <td>-0.394574</td>\n",
              "      <td>-0.424278</td>\n",
              "      <td>-0.900739</td>\n",
              "      <td>-0.504324</td>\n",
              "      <td>-0.805654</td>\n",
              "      <td>-0.602731</td>\n",
              "      <td>0.446372</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.157088</td>\n",
              "      <td>-0.175077</td>\n",
              "      <td>-0.530687</td>\n",
              "      <td>-0.672038</td>\n",
              "      <td>-0.657468</td>\n",
              "      <td>-0.644701</td>\n",
              "      <td>-0.619731</td>\n",
              "      <td>-0.867993</td>\n",
              "      <td>-0.672038</td>\n",
              "      <td>-0.939650</td>\n",
              "      <td>-0.633109</td>\n",
              "      <td>0.286826</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.031915</td>\n",
              "      <td>0.196921</td>\n",
              "      <td>-0.053556</td>\n",
              "      <td>0.260880</td>\n",
              "      <td>0.551742</td>\n",
              "      <td>-0.943773</td>\n",
              "      <td>-0.862899</td>\n",
              "      <td>-0.718009</td>\n",
              "      <td>0.292856</td>\n",
              "      <td>0.024920</td>\n",
              "      <td>6</td>\n",
              "      <td>WALKING_UPSTAIRS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10294</th>\n",
              "      <td>0.275424</td>\n",
              "      <td>-0.013164</td>\n",
              "      <td>-0.111728</td>\n",
              "      <td>-0.987426</td>\n",
              "      <td>-0.964183</td>\n",
              "      <td>-0.963635</td>\n",
              "      <td>-0.987753</td>\n",
              "      <td>-0.961550</td>\n",
              "      <td>-0.959371</td>\n",
              "      <td>-0.933464</td>\n",
              "      <td>-0.553330</td>\n",
              "      <td>-0.816103</td>\n",
              "      <td>0.841391</td>\n",
              "      <td>0.682535</td>\n",
              "      <td>0.824194</td>\n",
              "      <td>-0.973018</td>\n",
              "      <td>-0.999867</td>\n",
              "      <td>-0.999591</td>\n",
              "      <td>-0.998887</td>\n",
              "      <td>-0.987730</td>\n",
              "      <td>-0.958484</td>\n",
              "      <td>-0.953298</td>\n",
              "      <td>-0.444694</td>\n",
              "      <td>-0.337560</td>\n",
              "      <td>-0.435035</td>\n",
              "      <td>0.193448</td>\n",
              "      <td>-0.078580</td>\n",
              "      <td>0.095440</td>\n",
              "      <td>-0.430188</td>\n",
              "      <td>0.176352</td>\n",
              "      <td>-0.051043</td>\n",
              "      <td>-0.179078</td>\n",
              "      <td>0.227786</td>\n",
              "      <td>0.155175</td>\n",
              "      <td>-0.049247</td>\n",
              "      <td>-0.014286</td>\n",
              "      <td>-0.191090</td>\n",
              "      <td>0.768454</td>\n",
              "      <td>-0.782210</td>\n",
              "      <td>-0.741302</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.652236</td>\n",
              "      <td>-0.604383</td>\n",
              "      <td>-0.867906</td>\n",
              "      <td>-0.984014</td>\n",
              "      <td>-0.978058</td>\n",
              "      <td>-0.981196</td>\n",
              "      <td>-0.975506</td>\n",
              "      <td>-0.998599</td>\n",
              "      <td>-0.984014</td>\n",
              "      <td>-0.999689</td>\n",
              "      <td>-0.989812</td>\n",
              "      <td>-0.708857</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.041731</td>\n",
              "      <td>0.091474</td>\n",
              "      <td>-0.241239</td>\n",
              "      <td>-0.986320</td>\n",
              "      <td>-0.980671</td>\n",
              "      <td>-0.979370</td>\n",
              "      <td>-0.980042</td>\n",
              "      <td>-0.990852</td>\n",
              "      <td>-0.986320</td>\n",
              "      <td>-0.999813</td>\n",
              "      <td>-0.977360</td>\n",
              "      <td>-0.766676</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.359219</td>\n",
              "      <td>0.025541</td>\n",
              "      <td>-0.307330</td>\n",
              "      <td>0.079453</td>\n",
              "      <td>0.613975</td>\n",
              "      <td>0.599878</td>\n",
              "      <td>-0.066462</td>\n",
              "      <td>0.339324</td>\n",
              "      <td>-0.191734</td>\n",
              "      <td>-0.770902</td>\n",
              "      <td>13</td>\n",
              "      <td>LAYING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10295</th>\n",
              "      <td>0.286355</td>\n",
              "      <td>-0.035174</td>\n",
              "      <td>-0.140594</td>\n",
              "      <td>-0.470594</td>\n",
              "      <td>-0.161859</td>\n",
              "      <td>-0.270344</td>\n",
              "      <td>-0.490161</td>\n",
              "      <td>-0.213268</td>\n",
              "      <td>-0.264895</td>\n",
              "      <td>-0.395903</td>\n",
              "      <td>-0.174565</td>\n",
              "      <td>-0.264799</td>\n",
              "      <td>0.346166</td>\n",
              "      <td>0.088501</td>\n",
              "      <td>0.379623</td>\n",
              "      <td>-0.296573</td>\n",
              "      <td>-0.858538</td>\n",
              "      <td>-0.863000</td>\n",
              "      <td>-0.756991</td>\n",
              "      <td>-0.559967</td>\n",
              "      <td>-0.382987</td>\n",
              "      <td>-0.294528</td>\n",
              "      <td>0.562214</td>\n",
              "      <td>0.267704</td>\n",
              "      <td>0.160405</td>\n",
              "      <td>-0.202583</td>\n",
              "      <td>0.108813</td>\n",
              "      <td>-0.009053</td>\n",
              "      <td>0.099343</td>\n",
              "      <td>-0.387131</td>\n",
              "      <td>0.330866</td>\n",
              "      <td>0.046469</td>\n",
              "      <td>-0.134592</td>\n",
              "      <td>-0.351550</td>\n",
              "      <td>0.373417</td>\n",
              "      <td>-0.182795</td>\n",
              "      <td>-0.042505</td>\n",
              "      <td>-0.115855</td>\n",
              "      <td>-0.233603</td>\n",
              "      <td>0.442668</td>\n",
              "      <td>...</td>\n",
              "      <td>0.073954</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.130158</td>\n",
              "      <td>0.508801</td>\n",
              "      <td>0.323138</td>\n",
              "      <td>-0.605658</td>\n",
              "      <td>-0.649092</td>\n",
              "      <td>-0.591512</td>\n",
              "      <td>-0.712586</td>\n",
              "      <td>-0.945740</td>\n",
              "      <td>-0.605658</td>\n",
              "      <td>-0.914611</td>\n",
              "      <td>-0.569028</td>\n",
              "      <td>0.475735</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.184024</td>\n",
              "      <td>-0.488676</td>\n",
              "      <td>-0.784262</td>\n",
              "      <td>-0.635497</td>\n",
              "      <td>-0.650934</td>\n",
              "      <td>-0.644149</td>\n",
              "      <td>-0.621439</td>\n",
              "      <td>-0.845005</td>\n",
              "      <td>-0.635497</td>\n",
              "      <td>-0.931003</td>\n",
              "      <td>-0.615512</td>\n",
              "      <td>0.303259</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>0.230929</td>\n",
              "      <td>0.090169</td>\n",
              "      <td>-0.199039</td>\n",
              "      <td>-0.173484</td>\n",
              "      <td>0.313432</td>\n",
              "      <td>0.290348</td>\n",
              "      <td>-0.639894</td>\n",
              "      <td>-0.841003</td>\n",
              "      <td>0.146476</td>\n",
              "      <td>0.121483</td>\n",
              "      <td>24</td>\n",
              "      <td>WALKING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10296</th>\n",
              "      <td>0.278526</td>\n",
              "      <td>-0.016238</td>\n",
              "      <td>-0.112688</td>\n",
              "      <td>-0.991406</td>\n",
              "      <td>-0.985298</td>\n",
              "      <td>-0.983993</td>\n",
              "      <td>-0.992546</td>\n",
              "      <td>-0.983614</td>\n",
              "      <td>-0.984676</td>\n",
              "      <td>-0.938907</td>\n",
              "      <td>-0.566650</td>\n",
              "      <td>-0.820005</td>\n",
              "      <td>0.836562</td>\n",
              "      <td>0.687471</td>\n",
              "      <td>0.831674</td>\n",
              "      <td>-0.989097</td>\n",
              "      <td>-0.999926</td>\n",
              "      <td>-0.999901</td>\n",
              "      <td>-0.999635</td>\n",
              "      <td>-0.992995</td>\n",
              "      <td>-0.986239</td>\n",
              "      <td>-0.986916</td>\n",
              "      <td>-0.525672</td>\n",
              "      <td>-0.544409</td>\n",
              "      <td>-0.604819</td>\n",
              "      <td>0.236243</td>\n",
              "      <td>-0.110740</td>\n",
              "      <td>0.108338</td>\n",
              "      <td>0.002046</td>\n",
              "      <td>0.193312</td>\n",
              "      <td>-0.072326</td>\n",
              "      <td>0.047228</td>\n",
              "      <td>0.212749</td>\n",
              "      <td>0.383511</td>\n",
              "      <td>-0.305690</td>\n",
              "      <td>0.313782</td>\n",
              "      <td>-0.118524</td>\n",
              "      <td>0.568304</td>\n",
              "      <td>0.395917</td>\n",
              "      <td>0.399699</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.968254</td>\n",
              "      <td>0.542985</td>\n",
              "      <td>-0.769864</td>\n",
              "      <td>-0.950716</td>\n",
              "      <td>-0.986991</td>\n",
              "      <td>-0.983644</td>\n",
              "      <td>-0.982149</td>\n",
              "      <td>-0.988574</td>\n",
              "      <td>-0.998313</td>\n",
              "      <td>-0.986991</td>\n",
              "      <td>-0.999805</td>\n",
              "      <td>-0.988442</td>\n",
              "      <td>-0.704985</td>\n",
              "      <td>-0.743590</td>\n",
              "      <td>-0.236882</td>\n",
              "      <td>-0.455806</td>\n",
              "      <td>-0.809228</td>\n",
              "      <td>-0.994462</td>\n",
              "      <td>-0.993743</td>\n",
              "      <td>-0.993192</td>\n",
              "      <td>-0.995447</td>\n",
              "      <td>-0.998056</td>\n",
              "      <td>-0.994462</td>\n",
              "      <td>-0.999965</td>\n",
              "      <td>-0.995856</td>\n",
              "      <td>-0.955696</td>\n",
              "      <td>-0.936508</td>\n",
              "      <td>0.036973</td>\n",
              "      <td>-0.424845</td>\n",
              "      <td>-0.812114</td>\n",
              "      <td>-0.144943</td>\n",
              "      <td>0.028142</td>\n",
              "      <td>0.282356</td>\n",
              "      <td>0.561536</td>\n",
              "      <td>-0.594967</td>\n",
              "      <td>0.323425</td>\n",
              "      <td>0.184718</td>\n",
              "      <td>21</td>\n",
              "      <td>STANDING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10297</th>\n",
              "      <td>0.269661</td>\n",
              "      <td>-0.018530</td>\n",
              "      <td>-0.107585</td>\n",
              "      <td>-0.983395</td>\n",
              "      <td>-0.988092</td>\n",
              "      <td>-0.981767</td>\n",
              "      <td>-0.988162</td>\n",
              "      <td>-0.989536</td>\n",
              "      <td>-0.984313</td>\n",
              "      <td>-0.930790</td>\n",
              "      <td>-0.573230</td>\n",
              "      <td>-0.806475</td>\n",
              "      <td>0.815816</td>\n",
              "      <td>0.681191</td>\n",
              "      <td>0.841980</td>\n",
              "      <td>-0.988864</td>\n",
              "      <td>-0.999779</td>\n",
              "      <td>-0.999924</td>\n",
              "      <td>-0.999597</td>\n",
              "      <td>-0.995000</td>\n",
              "      <td>-0.991262</td>\n",
              "      <td>-0.986314</td>\n",
              "      <td>-0.584263</td>\n",
              "      <td>-0.707003</td>\n",
              "      <td>-0.512931</td>\n",
              "      <td>0.027415</td>\n",
              "      <td>-0.248636</td>\n",
              "      <td>0.299798</td>\n",
              "      <td>0.114343</td>\n",
              "      <td>0.100964</td>\n",
              "      <td>-0.107015</td>\n",
              "      <td>0.228625</td>\n",
              "      <td>0.091704</td>\n",
              "      <td>0.472050</td>\n",
              "      <td>-0.358434</td>\n",
              "      <td>0.426520</td>\n",
              "      <td>-0.151194</td>\n",
              "      <td>0.369610</td>\n",
              "      <td>-0.324489</td>\n",
              "      <td>-0.075425</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.237126</td>\n",
              "      <td>-0.258119</td>\n",
              "      <td>-0.568804</td>\n",
              "      <td>-0.986359</td>\n",
              "      <td>-0.977070</td>\n",
              "      <td>-0.978550</td>\n",
              "      <td>-0.980488</td>\n",
              "      <td>-0.994240</td>\n",
              "      <td>-0.986359</td>\n",
              "      <td>-0.999692</td>\n",
              "      <td>-0.995952</td>\n",
              "      <td>-0.727796</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.353042</td>\n",
              "      <td>-0.208436</td>\n",
              "      <td>-0.637516</td>\n",
              "      <td>-0.992919</td>\n",
              "      <td>-0.992728</td>\n",
              "      <td>-0.992178</td>\n",
              "      <td>-0.993221</td>\n",
              "      <td>-0.994647</td>\n",
              "      <td>-0.992919</td>\n",
              "      <td>-0.999952</td>\n",
              "      <td>-0.992142</td>\n",
              "      <td>-0.923452</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.017262</td>\n",
              "      <td>-0.300514</td>\n",
              "      <td>-0.655380</td>\n",
              "      <td>0.154557</td>\n",
              "      <td>-0.409579</td>\n",
              "      <td>-0.070852</td>\n",
              "      <td>0.540670</td>\n",
              "      <td>0.513343</td>\n",
              "      <td>-0.391982</td>\n",
              "      <td>-0.614962</td>\n",
              "      <td>30</td>\n",
              "      <td>LAYING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10298</th>\n",
              "      <td>0.291166</td>\n",
              "      <td>-0.018297</td>\n",
              "      <td>-0.105985</td>\n",
              "      <td>-0.974934</td>\n",
              "      <td>-0.977835</td>\n",
              "      <td>-0.992603</td>\n",
              "      <td>-0.975536</td>\n",
              "      <td>-0.976748</td>\n",
              "      <td>-0.993596</td>\n",
              "      <td>-0.908543</td>\n",
              "      <td>-0.561142</td>\n",
              "      <td>-0.811739</td>\n",
              "      <td>0.841771</td>\n",
              "      <td>0.689158</td>\n",
              "      <td>0.845938</td>\n",
              "      <td>-0.981088</td>\n",
              "      <td>-0.999543</td>\n",
              "      <td>-0.999819</td>\n",
              "      <td>-0.999869</td>\n",
              "      <td>-0.977155</td>\n",
              "      <td>-0.979794</td>\n",
              "      <td>-0.993276</td>\n",
              "      <td>-0.173047</td>\n",
              "      <td>-0.546057</td>\n",
              "      <td>-0.554710</td>\n",
              "      <td>-0.354281</td>\n",
              "      <td>0.187241</td>\n",
              "      <td>0.071455</td>\n",
              "      <td>-0.170924</td>\n",
              "      <td>0.047943</td>\n",
              "      <td>-0.079743</td>\n",
              "      <td>0.138828</td>\n",
              "      <td>-0.010669</td>\n",
              "      <td>0.299333</td>\n",
              "      <td>0.034378</td>\n",
              "      <td>-0.121391</td>\n",
              "      <td>0.217015</td>\n",
              "      <td>0.793135</td>\n",
              "      <td>-0.188010</td>\n",
              "      <td>-0.149274</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.619048</td>\n",
              "      <td>0.357807</td>\n",
              "      <td>-0.609239</td>\n",
              "      <td>-0.917307</td>\n",
              "      <td>-0.980821</td>\n",
              "      <td>-0.972300</td>\n",
              "      <td>-0.972283</td>\n",
              "      <td>-0.969414</td>\n",
              "      <td>-0.990220</td>\n",
              "      <td>-0.980821</td>\n",
              "      <td>-0.999539</td>\n",
              "      <td>-0.973568</td>\n",
              "      <td>-0.610815</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.335134</td>\n",
              "      <td>0.012244</td>\n",
              "      <td>-0.272497</td>\n",
              "      <td>-0.990935</td>\n",
              "      <td>-0.992274</td>\n",
              "      <td>-0.992057</td>\n",
              "      <td>-0.991076</td>\n",
              "      <td>-0.989857</td>\n",
              "      <td>-0.990935</td>\n",
              "      <td>-0.999937</td>\n",
              "      <td>-0.990068</td>\n",
              "      <td>-0.955696</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.172421</td>\n",
              "      <td>-0.110587</td>\n",
              "      <td>-0.366192</td>\n",
              "      <td>-0.018632</td>\n",
              "      <td>-0.774146</td>\n",
              "      <td>0.690323</td>\n",
              "      <td>-0.148849</td>\n",
              "      <td>0.774865</td>\n",
              "      <td>-0.046804</td>\n",
              "      <td>-0.927630</td>\n",
              "      <td>9</td>\n",
              "      <td>LAYING</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10299 rows × 563 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       tBodyAcc-mean()-X  tBodyAcc-mean()-Y  ...  subject            Activity\n",
              "0               0.275800           0.001837  ...        2  WALKING_DOWNSTAIRS\n",
              "1               0.239223          -0.031477  ...       20              LAYING\n",
              "2               0.272430          -0.017791  ...       27              LAYING\n",
              "3               0.266606          -0.019494  ...       22              LAYING\n",
              "4               0.212787          -0.048130  ...        6    WALKING_UPSTAIRS\n",
              "...                  ...                ...  ...      ...                 ...\n",
              "10294           0.275424          -0.013164  ...       13              LAYING\n",
              "10295           0.286355          -0.035174  ...       24             WALKING\n",
              "10296           0.278526          -0.016238  ...       21            STANDING\n",
              "10297           0.269661          -0.018530  ...       30              LAYING\n",
              "10298           0.291166          -0.018297  ...        9              LAYING\n",
              "\n",
              "[10299 rows x 563 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyJEio1rH2gq",
        "outputId": "814eba0d-b324-4d16-f0ef-ba59dc1ff5c3"
      },
      "source": [
        "len(DF_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2947"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cdwwMApahCj",
        "outputId": "b0d8ffa8-019e-4614-e703-9aaa082c8b24"
      },
      "source": [
        "test_split = 0.3\n",
        "\n",
        "random_clients = random.sample(range(1, 30), 5)\n",
        "print('Randomly Selected 5 clients: ', random_clients)\n",
        "\n",
        "C1_Train = DF[DF.subject == random_clients[0]].iloc[:int((1-test_split)*len(DF[DF.subject == random_clients[0]])), :]\n",
        "C2_Train = DF[DF.subject == random_clients[1]].iloc[:int((1-test_split)*len(DF[DF.subject == random_clients[1]])), :]\n",
        "C3_Train = DF[DF.subject == random_clients[2]].iloc[:int((1-test_split)*len(DF[DF.subject == random_clients[2]])), :]\n",
        "C4_Train = DF[DF.subject == random_clients[3]].iloc[:int((1-test_split)*len(DF[DF.subject == random_clients[3]])), :]\n",
        "C5_Train = DF[DF.subject == random_clients[4]].iloc[:int((1-test_split)*len(DF[DF.subject == random_clients[4]])), :]\n",
        "\n",
        "C1_Test = DF[DF.subject == random_clients[0]].iloc[int((1-test_split)*len(DF[DF.subject == random_clients[0]])):, :]\n",
        "C2_Test = DF[DF.subject == random_clients[1]].iloc[int((1-test_split)*len(DF[DF.subject == random_clients[1]])):, :]\n",
        "C3_Test = DF[DF.subject == random_clients[2]].iloc[int((1-test_split)*len(DF[DF.subject == random_clients[2]])):, :]\n",
        "C4_Test = DF[DF.subject == random_clients[3]].iloc[int((1-test_split)*len(DF[DF.subject == random_clients[3]])):, :]\n",
        "C5_Test = DF[DF.subject == random_clients[4]].iloc[int((1-test_split)*len(DF[DF.subject == random_clients[4]])):, :]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Randomly Selected 5 clients:  [9, 10, 4, 21, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVS1z9T-bZ_3"
      },
      "source": [
        "# Removing the data for our 5 clients from the training and testing sets\n",
        "Train = pd.concat([DF, pd.concat([C1_Train, C2_Train, C3_Train, C4_Train, C5_Train, C1_Test, C2_Test, C3_Test, C4_Test, C5_Test])]).drop_duplicates(keep=False).iloc[:int((1-test_split)*len(DF)), :]\n",
        "Test = pd.concat([DF, pd.concat([C1_Train, C2_Train, C3_Train, C4_Train, C5_Train, C1_Test, C2_Test, C3_Test, C4_Test, C5_Test])]).drop_duplicates(keep=False).iloc[int((1-test_split)*len(DF)):, :]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMiCR_TBcEQX"
      },
      "source": [
        "# ----------------------------- #\n",
        "# ---------- SETTINGS ----------#\n",
        "# ----------------------------- #\n",
        "\n",
        "NUM_Clients = 5 # number of clients contributing per training round\n",
        "\n",
        "# ML\n",
        "Cluster_Size = 100 # max client dataset size for training\n",
        "Batch_Size = 10\n",
        "NUM_Epoch = 3\n",
        "verbose = 1\n",
        "\n",
        "# Krum\n",
        "krum_f = 0.25 # percentage of byzantine nodes\n",
        "\n",
        "# Differential Privacy\n",
        "Gaussian_Noise = False\n",
        "Gaussian_Noise_Std_Dev = 0.25\n",
        "\n",
        "Gradient_Clipping = False\n",
        "Clip_Norm = 0.60\n",
        "\n",
        "Gradient_Pruning = False\n",
        "initial_sparsity = 0.00\n",
        "final_sparsity = 0.50\n",
        "\n",
        "# ---------------------------- #\n",
        "# ----------------------------- #\n",
        "# ----------------------------- #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_toqjFQdeB-W"
      },
      "source": [
        "def preprocess(df):\n",
        "  y_train = df.Activity\n",
        "  X_train = df.drop(['subject', 'Activity'], axis=1)\n",
        "  print('Training data size : ', X_train.shape)\n",
        "  labelencoder = LabelEncoder()\n",
        "  y_train = labelencoder.fit_transform(y_train)\n",
        "  y_train = to_categorical(y_train)\n",
        "  sc = StandardScaler()\n",
        "  X_train = sc.fit_transform(X_train)\n",
        "  print('X_Train Shape: ', X_train.shape)\n",
        "  print('y_Train Shape: ', y_train.shape)\n",
        "  return X_train, y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlwLba0DeDxo",
        "outputId": "1de7b404-d8a3-4128-97b2-78a96a1575ac"
      },
      "source": [
        "X_test, y_test = preprocess(Test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size :  (1481, 561)\n",
            "X_Train Shape:  (1481, 561)\n",
            "y_Train Shape:  (1481, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZxaF9K-eE3l"
      },
      "source": [
        "def train(name, X_train, y_train, globalId):\n",
        "\n",
        "  n_timesteps, n_features, n_outputs = X_train.shape[0], X_train.shape[1], y_train.shape[0]\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(100, activation='relu', input_dim=n_features))\n",
        "  if Gaussian_Noise == True:\n",
        "        model.add(GaussianNoise(Gaussian_Noise_Std_Dev))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "  if Gradient_Pruning == True:\n",
        "        end_step = np.ceil(n_timesteps / Batch_Size).astype(np.int32) * NUM_Epoch\n",
        "\n",
        "        # Define model for pruning.\n",
        "        pruning_params = {\n",
        "              'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=initial_sparsity,\n",
        "                                                                       final_sparsity=final_sparsity,\n",
        "                                                                       begin_step=0,\n",
        "                                                                       end_step=end_step)\n",
        "        }\n",
        "\n",
        "        logdir = tempfile.mkdtemp()\n",
        "\n",
        "        callbacks = [\n",
        "          tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "          tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "        ]\n",
        "\n",
        "        model = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "  if globalId != 1:\n",
        "        model.load_weights(\"./weights/global\"+str(globalId)+\".h5\")\n",
        "\n",
        "  if Gradient_Clipping == True:\n",
        "    opt = keras.optimizers.Adam(clipnorm=Clip_Norm)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  else: \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "      \n",
        "  if Gradient_Pruning == True:\n",
        "    history = model.fit(X_train, y_train, epochs=NUM_Epoch, batch_size=Batch_Size, verbose=1, callbacks=callbacks)\n",
        "  else:\n",
        "    history = model.fit(X_train, y_train, epochs=NUM_Epoch, batch_size=Batch_Size, verbose=1)\n",
        "  \n",
        "  #Saving Model\n",
        "  model.save(\"./weights/\"+str(name)+\".h5\")\n",
        "  return n_timesteps, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CATfh6HeearD"
      },
      "source": [
        "def euclidean(m, n):\n",
        "    # Finds eucledian distance between two ML models m & n\n",
        "    distance = []\n",
        "    for i in range(len(m)):\n",
        "        distance.append(euc(m[i].reshape(-1,1), n[i].reshape(-1,1)))\n",
        "    distance = sum(distance)/len(m)\n",
        "    return distance\n",
        "\n",
        "def saveModel(weight, n):\n",
        "    \n",
        "    num_classes=len(np.unique(y_test))\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(100, activation='relu', input_dim=561))\n",
        "    if Gaussian_Noise == True:\n",
        "          model.add(GaussianNoise(Gaussian_Noise_Std_Dev))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "    if Gradient_Pruning == True:\n",
        "          model = prune_low_magnitude(model)\n",
        "\n",
        "    model.set_weights(weight)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    scores = model.evaluate(X_test, y_test)\n",
        "    print(\"Loss: \", scores[0])        #Loss\n",
        "    print(\"Accuracy: \", scores[1])    #Accuracy\n",
        "\n",
        "    #Saving Model\n",
        "    fpath = \"./weights/global\"+str(n)+\".h5\"\n",
        "    model.save(fpath)\n",
        "    return scores[0], scores[1]\n",
        "\n",
        "def getDataLen(trainingDict):\n",
        "    n = 0\n",
        "    for w in trainingDict:\n",
        "        n += trainingDict[w]\n",
        "    print('Total number of data points after this round: ', n)\n",
        "    return n\n",
        "\n",
        "def assignWeights(trainingDf, trainingDict):\n",
        "    n = getDataLen(trainingDict)\n",
        "    trainingDf['Weightage'] = trainingDf['DataSize'].apply(lambda x: x/n)\n",
        "    return trainingDf, n\n",
        "    \n",
        "def scale(weight, scaler):\n",
        "    scaledWeights = []\n",
        "    for i in range(len(weight)):\n",
        "        scaledWeights.append(scaler * weight[i])\n",
        "    return scaledWeights\n",
        "\n",
        "def getScaledWeight(d, scaler):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(100, activation='relu', input_dim=561))\n",
        "    if Gaussian_Noise == True:\n",
        "          model.add(GaussianNoise(Gaussian_Noise_Std_Dev))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "    if Gradient_Pruning == True:\n",
        "        model = prune_low_magnitude(model)\n",
        "    fpath = \"./weights/\"+d+\".h5\"\n",
        "    model.load_weights(fpath)\n",
        "    weight = model.get_weights()\n",
        "    return scale(weight, scaler)\n",
        "\n",
        "def getWeight(d):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(100, activation='relu', input_dim=561))\n",
        "    if Gaussian_Noise == True:\n",
        "          model.add(GaussianNoise(Gaussian_Noise_Std_Dev))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "    if Gradient_Pruning == True:\n",
        "        model = prune_low_magnitude(model)\n",
        "    fpath = \"./weights/\"+d+\".h5\"\n",
        "    model.load_weights(fpath)\n",
        "    weight = model.get_weights()\n",
        "    return weight\n",
        "\n",
        "def avgWeights(scaledWeights):\n",
        "    avg = list()\n",
        "    for weight_list_tuple in zip(*scaledWeights):\n",
        "        layer_mean = tf.math.reduce_sum(weight_list_tuple, axis=0)\n",
        "        avg.append(layer_mean)\n",
        "    return avg\n",
        "\n",
        "def FedAvg(trainingDict):\n",
        "    trainingDf = pd.DataFrame.from_dict(trainingDict, orient='index', columns=['DataSize']) \n",
        "    models = list(trainingDict.keys())\n",
        "    scaledWeights = []\n",
        "    trainingDf, dataLen = assignWeights(trainingDf, trainingDict)\n",
        "    for m in models:\n",
        "        scaledWeights.append(getScaledWeight(m, trainingDf.loc[m]['Weightage']))\n",
        "    fedAvgWeight = avgWeights(scaledWeights)\n",
        "    return fedAvgWeight, dataLen\n",
        "\n",
        "def MK(trainingDict, b):\n",
        "    models = list(trainingDict.keys())\n",
        "    trainingDf = pd.DataFrame.from_dict(trainingDict, orient='index', columns=['DataSize'])\n",
        "    l_weights = []\n",
        "    g_weight = {}\n",
        "    for m in models:\n",
        "        if 'global' in m:\n",
        "            g_weight['name'] = m\n",
        "            g_weight['weight'] = getWeight(m)\n",
        "        else:\n",
        "            l_weights.append({\n",
        "                'name': m,\n",
        "                'weight': getWeight(m)\n",
        "            })\n",
        "    scores = {}\n",
        "    for m in l_weights:\n",
        "        scores[m['name']] = euclidean(m['weight'], g_weight['weight'])\n",
        "    sortedScores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1])}\n",
        "\n",
        "    b = int(len(scores)*b)\n",
        "    \n",
        "    selected = []\n",
        "    for i in range(b):\n",
        "        selected.append((sortedScores.popitem())[0])\n",
        "\n",
        "    newDict = {}\n",
        "    for i in trainingDict.keys():\n",
        "        if (((i not in selected) and ('global' not in i))):\n",
        "            newDict[i] = trainingDict[i]\n",
        "\n",
        "    print('Selections: ', newDict)\n",
        "    NewGlobal, dataLen = FedAvg(newDict)\n",
        "    return NewGlobal, dataLen\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kouWDq0e2JT"
      },
      "source": [
        "curr_local = 0\n",
        "curr_global = 0\n",
        "def fed():\n",
        "  global curr_local\n",
        "  global curr_global\n",
        "\n",
        "  local = {}\n",
        "  loss_array = []\n",
        "  acc_array = []\n",
        "  for i in range(0, len(Train), Cluster_Size):\n",
        "\n",
        "      if int(curr_global) == 0:\n",
        "        curr_global += 1\n",
        "        print('Current Global: ', curr_global)\n",
        "        name = 'global' + str(curr_global)\n",
        "        X_train, y_train = preprocess(Train[i:i+Cluster_Size])\n",
        "        l, m = train(name, X_train, y_train, curr_global)\n",
        "        local[name] = l\n",
        "\n",
        "      else:\n",
        "        print('Current Local: ', curr_local)\n",
        "        name = str('local'+str(curr_local))\n",
        "        curr_local += 1\n",
        "        X_train, y_train = preprocess(Train[i:i+Cluster_Size])\n",
        "        if X_train.shape[0]<=99:\n",
        "          continue\n",
        "        l, m = train(name, X_train, y_train, curr_global)\n",
        "        local[name] = l\n",
        "\n",
        "        if (int(curr_local)%NUM_Clients == 0) and (curr_local != 0):\n",
        "          curr_global += 1\n",
        "          print('Current Global: ', curr_global)\n",
        "          name = 'global' + str(curr_global)\n",
        "          m, l = MK(local, krum_f)\n",
        "          loss, acc = saveModel(m, curr_global)\n",
        "          loss_array.append(loss)\n",
        "          acc_array.append(acc)\n",
        "          local = {}\n",
        "          local[name] = l\n",
        "  return acc_array, loss_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fvM4q7re4cg",
        "outputId": "bc8f80ab-ac46-4f93-812d-986e2bea7967"
      },
      "source": [
        "fed()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Global:  1\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 1s 2ms/step - loss: 1.7357 - accuracy: 0.2964\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7289 - accuracy: 0.7625\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7743\n",
            "Current Local:  0\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6581 - accuracy: 0.3119\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7491 - accuracy: 0.6947\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.8028\n",
            "Current Local:  1\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0213 - accuracy: 0.2788\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9452 - accuracy: 0.5782\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8886\n",
            "Current Local:  2\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7236 - accuracy: 0.3280\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8264 - accuracy: 0.6309\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.8295\n",
            "Current Local:  3\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6460 - accuracy: 0.3184\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8819 - accuracy: 0.5935\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7828\n",
            "Current Local:  4\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6127 - accuracy: 0.3747\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7208 - accuracy: 0.6821\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8080\n",
            "Current Global:  2\n",
            "Selections:  {'local0': 100, 'local2': 100, 'local3': 100, 'local4': 100}\n",
            "Total number of data points after this round:  400\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 1.6127 - accuracy: 0.4925\n",
            "Loss:  1.6105306148529053\n",
            "Accuracy:  0.5037137269973755\n",
            "Current Local:  5\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4794 - accuracy: 0.4296\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0203 - accuracy: 0.4711\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.8405 - accuracy: 0.6714\n",
            "Current Local:  6\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4580 - accuracy: 0.5931\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9034 - accuracy: 0.7091\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.7741\n",
            "Current Local:  7\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4173 - accuracy: 0.4780\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.9249 - accuracy: 0.6082\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7760 - accuracy: 0.6523\n",
            "Current Local:  8\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4783 - accuracy: 0.4599\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9658 - accuracy: 0.5950\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.7890\n",
            "Current Local:  9\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 1s 2ms/step - loss: 1.4870 - accuracy: 0.4353\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.9743 - accuracy: 0.6826\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.8105\n",
            "Current Global:  3\n",
            "Selections:  {'local5': 100, 'local7': 100, 'local8': 100, 'local9': 100}\n",
            "Total number of data points after this round:  400\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.8220\n",
            "Loss:  0.6908660531044006\n",
            "Accuracy:  0.8203916549682617\n",
            "Current Local:  10\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7505 - accuracy: 0.7492\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.7429\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8633\n",
            "Current Local:  11\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7988 - accuracy: 0.7482\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7846\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.8428\n",
            "Current Local:  12\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.7628 - accuracy: 0.7116\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7769\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8833\n",
            "Current Local:  13\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.7209\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7885\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8794\n",
            "Current Local:  14\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.7163 - accuracy: 0.7464\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7920\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8966\n",
            "Current Global:  4\n",
            "Selections:  {'local10': 100, 'local11': 100, 'local12': 100, 'local14': 100}\n",
            "Total number of data points after this round:  400\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8273\n",
            "Loss:  0.44823262095451355\n",
            "Accuracy:  0.8332207798957825\n",
            "Current Local:  15\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8535\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3000 - accuracy: 0.9008\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2939 - accuracy: 0.9024\n",
            "Current Local:  16\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8423\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.8365\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.9392\n",
            "Current Local:  17\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.7715\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8911\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.9297\n",
            "Current Local:  18\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7987\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.9077\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.8590\n",
            "Current Local:  19\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.7945\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7943\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8679\n",
            "Current Global:  5\n",
            "Selections:  {'local15': 100, 'local16': 100, 'local17': 100, 'local18': 100}\n",
            "Total number of data points after this round:  400\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8777\n",
            "Loss:  0.31242284178733826\n",
            "Accuracy:  0.8838622570037842\n",
            "Current Local:  20\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8645\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9221\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1543 - accuracy: 0.9741\n",
            "Current Local:  21\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 1s 3ms/step - loss: 0.4257 - accuracy: 0.8238\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3137 - accuracy: 0.8509\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1728 - accuracy: 0.9313\n",
            "Current Local:  22\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.9076\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9097\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.9547\n",
            "Current Local:  23\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8392\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8248\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9396\n",
            "Current Local:  24\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.7850\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8658\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2974 - accuracy: 0.8533\n",
            "Current Global:  6\n",
            "Selections:  {'local21': 100, 'local22': 100, 'local23': 100, 'local24': 100}\n",
            "Total number of data points after this round:  400\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.9057\n",
            "Loss:  0.2495577335357666\n",
            "Accuracy:  0.9068197011947632\n",
            "Current Local:  25\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8753\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8910\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.9432\n",
            "Current Local:  26\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.9140\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.9599\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9620\n",
            "Current Local:  27\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.8699\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9487\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9779\n",
            "Current Local:  28\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8715\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2471 - accuracy: 0.8988\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.9263\n",
            "Current Local:  29\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9132\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8855\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1330 - accuracy: 0.9480\n",
            "Current Global:  7\n",
            "Selections:  {'local25': 100, 'local27': 100, 'local28': 100, 'local29': 100}\n",
            "Total number of data points after this round:  400\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2045 - accuracy: 0.9134\n",
            "Loss:  0.19763822853565216\n",
            "Accuracy:  0.922349750995636\n",
            "Current Local:  30\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.8784\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.8560\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1841 - accuracy: 0.9076\n",
            "Current Local:  31\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2836 - accuracy: 0.8831\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9363\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.9861\n",
            "Current Local:  32\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 1s 3ms/step - loss: 0.2883 - accuracy: 0.8817\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1810 - accuracy: 0.9122\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.9444\n",
            "Current Local:  33\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.8745\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.9627\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1124 - accuracy: 0.9972\n",
            "Current Local:  34\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8247\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.9456\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.9618\n",
            "Current Global:  8\n",
            "Selections:  {'local30': 100, 'local31': 100, 'local32': 100, 'local34': 100}\n",
            "Total number of data points after this round:  400\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 0.9298\n",
            "Loss:  0.17301638424396515\n",
            "Accuracy:  0.9358541369438171\n",
            "Current Local:  35\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9511\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.9188\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9954\n",
            "Current Local:  36\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1607 - accuracy: 0.9313\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0870 - accuracy: 0.9725\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9932\n",
            "Current Local:  37\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.9014\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1694 - accuracy: 0.9007\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 1.0000\n",
            "Current Local:  38\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1658 - accuracy: 0.9625\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9929\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0798 - accuracy: 0.9685\n",
            "Current Local:  39\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1663 - accuracy: 0.9614\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.9644\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9960\n",
            "Current Global:  9\n",
            "Selections:  {'local35': 100, 'local37': 100, 'local38': 100, 'local39': 100}\n",
            "Total number of data points after this round:  400\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9436\n",
            "Loss:  0.14828135073184967\n",
            "Accuracy:  0.945307195186615\n",
            "Current Local:  40\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1894 - accuracy: 0.9160\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9472\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9441\n",
            "Current Local:  41\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9225\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9533\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9960\n",
            "Current Local:  42\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9579\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9225\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9576\n",
            "Current Local:  43\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9282\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9537\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9754\n",
            "Current Local:  44\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1517 - accuracy: 0.9518\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.9436\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9726\n",
            "Current Global:  10\n",
            "Selections:  {'local40': 100, 'local42': 100, 'local43': 100, 'local44': 100}\n",
            "Total number of data points after this round:  400\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9256\n",
            "Loss:  0.16707688570022583\n",
            "Accuracy:  0.9291019439697266\n",
            "Current Local:  45\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.9178\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9413\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0786 - accuracy: 0.9780\n",
            "Current Local:  46\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2722 - accuracy: 0.8622\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.9104\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9211\n",
            "Current Local:  47\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1088 - accuracy: 0.9615\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2060 - accuracy: 0.9158\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1378 - accuracy: 0.9528\n",
            "Current Local:  48\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1211 - accuracy: 0.9725\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9621\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9835\n",
            "Current Local:  49\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9447\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.9574\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9828\n",
            "Current Global:  11\n",
            "Selections:  {'local46': 100, 'local47': 100, 'local48': 100, 'local49': 100}\n",
            "Total number of data points after this round:  400\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9552\n",
            "Loss:  0.12153568118810654\n",
            "Accuracy:  0.9513841867446899\n",
            "Current Local:  50\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1269 - accuracy: 0.9478\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9363\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9878\n",
            "Current Local:  51\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1915 - accuracy: 0.9208\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1293 - accuracy: 0.9212\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0738 - accuracy: 0.9754\n",
            "Current Local:  52\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9730\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9982\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 0.9861\n",
            "Current Local:  53\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1645 - accuracy: 0.9273\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1532 - accuracy: 0.8991\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9724\n",
            "Current Local:  54\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1962 - accuracy: 0.9081\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9602\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.9914\n",
            "Current Global:  12\n",
            "Selections:  {'local50': 100, 'local52': 100, 'local53': 100, 'local54': 100}\n",
            "Total number of data points after this round:  400\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1203 - accuracy: 0.9538\n",
            "Loss:  0.12394406646490097\n",
            "Accuracy:  0.9561107158660889\n",
            "Current Local:  55\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9685\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1388 - accuracy: 0.9462\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9586\n",
            "Current Local:  56\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 0.9793\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9787\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9833\n",
            "Current Local:  57\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9043\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9893\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9700\n",
            "Current Local:  58\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1367 - accuracy: 0.9577\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9964\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9662\n",
            "Current Local:  59\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9314\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.9633\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9590\n",
            "Current Global:  13\n",
            "Selections:  {'local55': 100, 'local56': 100, 'local58': 100, 'local59': 100}\n",
            "Total number of data points after this round:  400\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9460\n",
            "Loss:  0.12955030798912048\n",
            "Accuracy:  0.948008120059967\n",
            "Current Local:  60\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1641 - accuracy: 0.9375\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9614\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9880\n",
            "Current Local:  61\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9496\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9932\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Current Local:  62\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1104 - accuracy: 0.9640\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9621\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9896\n",
            "Current Local:  63\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9623\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9667\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9725\n",
            "Current Local:  64\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.9758\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9879\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.9972\n",
            "Current Global:  14\n",
            "Selections:  {'local60': 100, 'local62': 100, 'local63': 100, 'local64': 100}\n",
            "Total number of data points after this round:  400\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1115 - accuracy: 0.9564\n",
            "Loss:  0.10837368667125702\n",
            "Accuracy:  0.9574611783027649\n",
            "Current Local:  65\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1345 - accuracy: 0.9671\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1856 - accuracy: 0.9290\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9586\n",
            "Current Local:  66\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9620\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.9553\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 1.0000\n",
            "Current Local:  67\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1313 - accuracy: 0.9525\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9629\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.9616\n",
            "Current Local:  68\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 1s 2ms/step - loss: 0.1330 - accuracy: 0.9492\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9896\n",
            "Current Local:  69\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9616\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9843\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 1.0000\n",
            "Current Global:  15\n",
            "Selections:  {'local65': 100, 'local66': 100, 'local67': 100, 'local69': 100}\n",
            "Total number of data points after this round:  400\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9522\n",
            "Loss:  0.12818479537963867\n",
            "Accuracy:  0.9534098505973816\n",
            "Current Local:  70\n",
            "Training data size :  (100, 561)\n",
            "X_Train Shape:  (100, 561)\n",
            "y_Train Shape:  (100, 6)\n",
            "Epoch 1/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1133 - accuracy: 0.9433\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.9725\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 1.0000\n",
            "Current Local:  71\n",
            "Training data size :  (9, 561)\n",
            "X_Train Shape:  (9, 561)\n",
            "y_Train Shape:  (9, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.5037137269973755,\n",
              "  0.8203916549682617,\n",
              "  0.8332207798957825,\n",
              "  0.8838622570037842,\n",
              "  0.9068197011947632,\n",
              "  0.922349750995636,\n",
              "  0.9358541369438171,\n",
              "  0.945307195186615,\n",
              "  0.9291019439697266,\n",
              "  0.9513841867446899,\n",
              "  0.9561107158660889,\n",
              "  0.948008120059967,\n",
              "  0.9574611783027649,\n",
              "  0.9534098505973816],\n",
              " [1.6105306148529053,\n",
              "  0.6908660531044006,\n",
              "  0.44823262095451355,\n",
              "  0.31242284178733826,\n",
              "  0.2495577335357666,\n",
              "  0.19763822853565216,\n",
              "  0.17301638424396515,\n",
              "  0.14828135073184967,\n",
              "  0.16707688570022583,\n",
              "  0.12153568118810654,\n",
              "  0.12394406646490097,\n",
              "  0.12955030798912048,\n",
              "  0.10837368667125702,\n",
              "  0.12818479537963867])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhL_n24S6iWs"
      },
      "source": [
        "def getNoTL(X_test, y_test, curr_global):\n",
        "    num_classes=len(np.unique(y_test))\n",
        "\n",
        "    inner_model = Sequential(\n",
        "    [\n",
        "        Dense(100, activation='relu', input_dim=561)\n",
        "    ]\n",
        ")\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(inner_model)\n",
        "\n",
        "    if Gaussian_Noise == True:\n",
        "          model.add(GaussianNoise(Gaussian_Noise_Std_Dev))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "\n",
        "    if Gradient_Pruning == True:\n",
        "          end_step = np.ceil(16500 / Batch_Size).astype(np.int32) * NUM_Epoch\n",
        "\n",
        "          # Define model for pruning.\n",
        "          pruning_params = {\n",
        "                'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=initial_sparsity,\n",
        "                                                                        final_sparsity=final_sparsity,\n",
        "                                                                        begin_step=0,\n",
        "                                                                        end_step=end_step)\n",
        "          }\n",
        "\n",
        "          logdir = tempfile.mkdtemp()\n",
        "\n",
        "          callbacks = [\n",
        "            tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "            tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "          ]\n",
        "\n",
        "          model = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "    model.load_weights(\"./weights/global\"+str(curr_global)+\".h5\")\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "      \n",
        "    scores = model.evaluate(X_test, y_test)\n",
        "    print(\"NoTL Loss: \", scores[0])        #Loss\n",
        "    print(\"NoTL Accuracy: \", scores[1])    #Accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsVL7hzxB0aa"
      },
      "source": [
        "def getGlobalTest(testdf, curr_global):\n",
        "\n",
        "    X_test, y_test = preprocess(testdf)\n",
        "\n",
        "    num_classes=len(np.unique(y_test))\n",
        "\n",
        "    inner_model = Sequential(\n",
        "    [\n",
        "        Dense(100, activation='relu', input_dim=561)\n",
        "    ]\n",
        ")\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(inner_model)\n",
        "\n",
        "    if Gaussian_Noise == True:\n",
        "          model.add(GaussianNoise(Gaussian_Noise_Std_Dev))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "\n",
        "    if Gradient_Pruning == True:\n",
        "          end_step = np.ceil(16500 / Batch_Size).astype(np.int32) * NUM_Epoch\n",
        "\n",
        "          # Define model for pruning.\n",
        "          pruning_params = {\n",
        "                'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=initial_sparsity,\n",
        "                                                                        final_sparsity=final_sparsity,\n",
        "                                                                        begin_step=0,\n",
        "                                                                        end_step=end_step)\n",
        "          }\n",
        "\n",
        "          logdir = tempfile.mkdtemp()\n",
        "\n",
        "          callbacks = [\n",
        "            tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "            tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "          ]\n",
        "\n",
        "          model = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "    model.load_weights(\"./weights/global\"+str(curr_global)+\".h5\")\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "      \n",
        "    scores = model.evaluate(X_test, y_test)\n",
        "    print(\"GlobalTest Loss: \", scores[0])        #Loss\n",
        "    print(\"GlobalTestA Accuracy: \", scores[1])    #Accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQNOMD2JhFM5"
      },
      "source": [
        "def TransferLearn(name, traindf, testdf):\n",
        "  global curr_global\n",
        "  X_train, y_train = preprocess(traindf)\n",
        "  X_test, y_test = preprocess(testdf)\n",
        "\n",
        "  n_timesteps, n_features, n_outputs = X_train.shape[0], X_train.shape[1], y_train.shape[0]\n",
        "\n",
        "  inner_model = Sequential(\n",
        "    [\n",
        "        Dense(100, activation='relu', input_dim=561)\n",
        "    ]\n",
        ")\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(inner_model)\n",
        "\n",
        "  if Gaussian_Noise == True:\n",
        "        model.add(GaussianNoise(Gaussian_Noise_Std_Dev))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "\n",
        "  if Gradient_Pruning == True:\n",
        "        end_step = np.ceil(n_timesteps / Batch_Size).astype(np.int32) * NUM_Epoch\n",
        "\n",
        "        # Define model for pruning.\n",
        "        pruning_params = {\n",
        "              'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=initial_sparsity,\n",
        "                                                                       final_sparsity=final_sparsity,\n",
        "                                                                       begin_step=0,\n",
        "                                                                       end_step=end_step)\n",
        "        }\n",
        "\n",
        "        logdir = tempfile.mkdtemp()\n",
        "\n",
        "        callbacks = [\n",
        "          tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "          tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "        ]\n",
        "\n",
        "        model = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "  model.load_weights(\"./weights/global\"+str(curr_global)+\".h5\")\n",
        "\n",
        "  if Gradient_Clipping == True:\n",
        "    opt = keras.optimizers.Adam(clipnorm=Clip_Norm)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  else: \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  for layer in inner_model.layers:#freezing layers to retain the weights \n",
        "\t  layer.trainable = False\n",
        "      \n",
        "  if Gradient_Pruning == True:\n",
        "    history = model.fit(X_train, y_train, epochs=5, batch_size=Batch_Size, verbose=1, callbacks=callbacks)\n",
        "  else:\n",
        "    history = model.fit(X_train, y_train, epochs=5, batch_size=Batch_Size, verbose=1)\n",
        "\n",
        "  history2 = model.evaluate(X_test, y_test, batch_size=Batch_Size, verbose=1)\n",
        "\n",
        "  test_accuracy = history2[1]\n",
        "  print(f\"The test accuracy after Transfer Learning is {test_accuracy}\")\n",
        "\n",
        "  getNoTL(X_test, y_test, curr_global)\n",
        "  getGlobalTest(Test, curr_global)\n",
        "\n",
        "  X_test_G, y_test_G = preprocess(Test)\n",
        "\n",
        "  s3 = model.evaluate(X_test_G, y_test_G, batch_size=Batch_Size, verbose=1)\n",
        "\n",
        "  print(\"After TL Global Test Loss: \", s3[0])        #Loss\n",
        "  print(\"After TL Global Test Accuracy: \", s3[1])    #Accuracy\n",
        "\n",
        "\n",
        "  \n",
        "  #Saving Model\n",
        "  model.save(\"./weights/\"+str(name)+\".h5\")\n",
        "  return n_timesteps, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Phzn9ndjMoX",
        "outputId": "b5b1b7d8-d837-471b-deaa-ea88779bf81e"
      },
      "source": [
        "TransferLearn('C1', C1_Train, C1_Test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size :  (201, 561)\n",
            "X_Train Shape:  (201, 561)\n",
            "y_Train Shape:  (201, 6)\n",
            "Training data size :  (87, 561)\n",
            "X_Train Shape:  (87, 561)\n",
            "y_Train Shape:  (87, 6)\n",
            "Epoch 1/5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8770\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.8787\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 0.1832 - accuracy: 0.9073\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 0.0980 - accuracy: 0.9486\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9713\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9425\n",
            "The test accuracy after Transfer Learning is 0.9425287246704102\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.8026\n",
            "NoTL Loss:  0.5927228331565857\n",
            "NoTL Accuracy:  0.8160919547080994\n",
            "Training data size :  (1481, 561)\n",
            "X_Train Shape:  (1481, 561)\n",
            "y_Train Shape:  (1481, 6)\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9522\n",
            "GlobalTest Loss:  0.12818479537963867\n",
            "GlobalTestA Accuracy:  0.9534098505973816\n",
            "Training data size :  (1481, 561)\n",
            "X_Train Shape:  (1481, 561)\n",
            "y_Train Shape:  (1481, 6)\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 0.1640 - accuracy: 0.9386\n",
            "After TL Global Test Loss:  0.16397957503795624\n",
            "After TL Global Test Accuracy:  0.9385550022125244\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(201, <tensorflow.python.keras.engine.sequential.Sequential at 0x7f28de31f5d0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p71sIVyEjnX5",
        "outputId": "880a29c4-852b-4870-fb05-17d66fcfb5a1"
      },
      "source": [
        "TransferLearn('C2', C2_Train, C2_Test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size :  (205, 561)\n",
            "X_Train Shape:  (205, 561)\n",
            "y_Train Shape:  (205, 6)\n",
            "Training data size :  (89, 561)\n",
            "X_Train Shape:  (89, 561)\n",
            "y_Train Shape:  (89, 6)\n",
            "Epoch 1/5\n",
            "21/21 [==============================] - 1s 2ms/step - loss: 0.2849 - accuracy: 0.9231\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.9857\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9905\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9951\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "The test accuracy after Transfer Learning is 1.0\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.3222 - accuracy: 0.8571\n",
            "NoTL Loss:  0.3989662528038025\n",
            "NoTL Accuracy:  0.8314606547355652\n",
            "Training data size :  (1481, 561)\n",
            "X_Train Shape:  (1481, 561)\n",
            "y_Train Shape:  (1481, 6)\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9522\n",
            "GlobalTest Loss:  0.12818479537963867\n",
            "GlobalTestA Accuracy:  0.9534098505973816\n",
            "Training data size :  (1481, 561)\n",
            "X_Train Shape:  (1481, 561)\n",
            "y_Train Shape:  (1481, 6)\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9345\n",
            "After TL Global Test Loss:  0.21341124176979065\n",
            "After TL Global Test Accuracy:  0.9345037341117859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(205, <tensorflow.python.keras.engine.sequential.Sequential at 0x7f28e5d96510>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbUktuHj1UBV",
        "outputId": "bdd2527a-8b7f-4258-bdd6-b8be8103f1dd"
      },
      "source": [
        "TransferLearn('C3', C3_Train, C3_Test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size :  (221, 561)\n",
            "X_Train Shape:  (221, 561)\n",
            "y_Train Shape:  (221, 6)\n",
            "Training data size :  (96, 561)\n",
            "X_Train Shape:  (96, 561)\n",
            "y_Train Shape:  (96, 6)\n",
            "Epoch 1/5\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9549\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9683\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9806\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9973\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9792\n",
            "The test accuracy after Transfer Learning is 0.9791666865348816\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9466\n",
            "NoTL Loss:  0.1253236085176468\n",
            "NoTL Accuracy:  0.9479166865348816\n",
            "Training data size :  (1481, 561)\n",
            "X_Train Shape:  (1481, 561)\n",
            "y_Train Shape:  (1481, 6)\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9522\n",
            "GlobalTest Loss:  0.12818479537963867\n",
            "GlobalTestA Accuracy:  0.9534098505973816\n",
            "Training data size :  (1481, 561)\n",
            "X_Train Shape:  (1481, 561)\n",
            "y_Train Shape:  (1481, 6)\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9379\n",
            "After TL Global Test Loss:  0.18272791802883148\n",
            "After TL Global Test Accuracy:  0.9378798007965088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(221, <tensorflow.python.keras.engine.sequential.Sequential at 0x7f28f60dee90>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnovv-uM1VkA",
        "outputId": "c47c3f85-1240-4d8c-ad13-4155a7a70b8c"
      },
      "source": [
        "TransferLearn('C4', C4_Train, C4_Test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size :  (285, 561)\n",
            "X_Train Shape:  (285, 561)\n",
            "y_Train Shape:  (285, 6)\n",
            "Training data size :  (123, 561)\n",
            "X_Train Shape:  (123, 561)\n",
            "y_Train Shape:  (123, 6)\n",
            "Epoch 1/5\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.9005\n",
            "Epoch 2/5\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9765\n",
            "Epoch 3/5\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9960\n",
            "Epoch 4/5\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 0.9976\n",
            "Epoch 5/5\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9946\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 1.0000\n",
            "The test accuracy after Transfer Learning is 1.0\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2169 - accuracy: 0.9280\n",
            "NoTL Loss:  0.23926423490047455\n",
            "NoTL Accuracy:  0.9268292784690857\n",
            "Training data size :  (1481, 561)\n",
            "X_Train Shape:  (1481, 561)\n",
            "y_Train Shape:  (1481, 6)\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9522\n",
            "GlobalTest Loss:  0.12818479537963867\n",
            "GlobalTestA Accuracy:  0.9534098505973816\n",
            "Training data size :  (1481, 561)\n",
            "X_Train Shape:  (1481, 561)\n",
            "y_Train Shape:  (1481, 6)\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9372\n",
            "After TL Global Test Loss:  0.20181512832641602\n",
            "After TL Global Test Accuracy:  0.9372045993804932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(285, <tensorflow.python.keras.engine.sequential.Sequential at 0x7f28dfd3b650>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4fQYFak1Xfj",
        "outputId": "740c93e4-f97d-4ea6-8f17-0e8425a9e344"
      },
      "source": [
        "TransferLearn('C5', C5_Train, C5_Test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size :  (211, 561)\n",
            "X_Train Shape:  (211, 561)\n",
            "y_Train Shape:  (211, 6)\n",
            "Training data size :  (91, 561)\n",
            "X_Train Shape:  (91, 561)\n",
            "y_Train Shape:  (91, 6)\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8962\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.9338\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1159 - accuracy: 0.9522\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9689\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9926\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9670\n",
            "The test accuracy after Transfer Learning is 0.9670329689979553\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.3124 - accuracy: 0.9021\n",
            "NoTL Loss:  0.3909125328063965\n",
            "NoTL Accuracy:  0.8901098966598511\n",
            "Training data size :  (1481, 561)\n",
            "X_Train Shape:  (1481, 561)\n",
            "y_Train Shape:  (1481, 6)\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9522\n",
            "GlobalTest Loss:  0.12818479537963867\n",
            "GlobalTestA Accuracy:  0.9534098505973816\n",
            "Training data size :  (1481, 561)\n",
            "X_Train Shape:  (1481, 561)\n",
            "y_Train Shape:  (1481, 6)\n",
            "149/149 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9399\n",
            "After TL Global Test Loss:  0.18287242949008942\n",
            "After TL Global Test Accuracy:  0.9399054646492004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(211, <tensorflow.python.keras.engine.sequential.Sequential at 0x7f28e5d8e050>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExXGUhltihv3",
        "outputId": "70069ba0-e148-4dbe-8ab8-1349839cd857"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " hapt-fl.png   mnist\t      rt_reviews.csv   train.csv\t  weights\n",
            " malaria       mnist-fl.png   test.csv\t      'UCI HAR Dataset'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msp3SvEXi2jt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdjo7Hoip4-6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}